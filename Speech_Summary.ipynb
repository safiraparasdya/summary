{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be58b994-bc68-4166-91d5-282418b78864",
      "metadata": {
        "id": "be58b994-bc68-4166-91d5-282418b78864"
      },
      "source": [
        "# Speech Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bjdJiIeB_jYN",
      "metadata": {
        "id": "bjdJiIeB_jYN"
      },
      "outputs": [],
      "source": [
        "# Summarizing Speech Text: http://obamaspeeches.com/005-Remarks-of-TechNet-Obama-Speech.htm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
        "outputId": "f210f7dd-9fdc-4cc8-877e-a175ed3740ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, safetensors, dill, responses, multiprocess, huggingface_hub, tokenizers, transformers, datasets, evaluate\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 evaluate-0.4.1 huggingface_hub-0.17.3 multiprocess-0.70.15 responses-0.18.0 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0 xxhash-3.4.1\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate huggingface_hub\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AzsA9RoQzd4w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzsA9RoQzd4w",
        "outputId": "1aa13735-d100-46ff-f854-aa53930a8e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m1.4/1.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai==0.27.0 tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0L3mI5v1zd7H",
      "metadata": {
        "id": "0L3mI5v1zd7H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-uS3yb8Jzd94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uS3yb8Jzd94",
        "outputId": "4908a48a-82dd-488f-f35e-94835c30dd34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.314\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, anyio, async-timeout, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5QTXnuDE0ceG",
      "metadata": {
        "id": "5QTXnuDE0ceG"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, PromptTemplate, LLMChain\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ko8NuBE60cfC",
      "metadata": {
        "id": "Ko8NuBE60cfC"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U-QqdOyX0cge",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-QqdOyX0cge",
        "outputId": "a443bdf9-e1ae-42bb-b18d-5156c9597d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# read data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F8kqZU2x6z8Z",
      "metadata": {
        "id": "F8kqZU2x6z8Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "root_dir = '/content/gdrive/My Drive'\n",
        "\n",
        "txt_files = [file for file in os.listdir(f'{root_dir}/Speech/') if file.endswith('.txt')]\n",
        "\n",
        "documents_combined = \"\"\n",
        "\n",
        "for txt_file in txt_files:\n",
        "    with open(f'{root_dir}/Speech/{txt_file}', 'r') as file:\n",
        "        document_content = file.read()\n",
        "        documents_combined += document_content\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSKTQD2C6lMc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSKTQD2C6lMc",
        "outputId": "fa1184fd-fa74-49f9-93a7-5ea45747c84b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(documents_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4h7wqr776h3W",
      "metadata": {
        "id": "4h7wqr776h3W"
      },
      "outputs": [],
      "source": [
        "texts = text_splitter.split_text(documents_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W2rDJXVc3eF2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2rDJXVc3eF2",
        "outputId": "72c01a3c-0e8a-4e6a-c5d7-5f27de23f988"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sgwzwnwc3hHQ",
      "metadata": {
        "id": "Sgwzwnwc3hHQ"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs = [Document(page_content=t) for t in texts[:2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kez5iLV73hJe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kez5iLV73hJe",
        "outputId": "2e941592-2884-4a11-f083-238cf4be4eb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='\\ufeff\\xa0\\xa0REMARKS OF SENATOR OBAMA AT TECHNET'),\n",
              " Document(page_content='Tuesday,\\xa0March 8, 2005\\u2028Remarks at TechNet\\u2028\\nThank you John Doer. It\\'s great to be here with all of you today, and I\\'m honored that you\\'ve given me the opportunity to join this discussion about the role technology can play in our future and our children\\'s future. And before we begin, I\\'d just like to recognize your CEO, Rick White, who is leaving TechNet after years of inspired leadership and service to this organization and this country. Thank you Rick.\\nWe\\'re here today because when it comes to the global economy, the rules of the game have changed. This is a fact not only understood by a roomful of Silicon Valley CEOs, but by families I met all across Illinois during the campaign. They know that when it comes to their jobs and their wages, they\\'re not only competing with workers in Naperville and Carbondale, but in New Delhi and Calcutta. What\\'s more, they know that when it comes to the high-tech, high skill jobs of the future, their children are not only competing with children here in the United States, but with those on the other side of the globe who are increasingly being educated earlier, longer, and with a special emphasis on the math and science skills required for the industries of tomorrow.\\nThese families tell me that they\\'re anxious about their future. They worry that they could become the first generation of Americans to see their children do worse than they did. They remember that when we were all growing up, our parents knew that if they pushed us to study and work hard, the best universities would be open to us and we could get any job we wanted. But today, parents in cities and towns all over America are losing that hope - they\\'re losing the sense that their kids will be able to dream the American dream.\\nThe rules of the game have changed. And so we must change with them. But in a country of innovators and optimists - a country that pioneered the first moon landing, discovered the cure for polio, and led the technological revolution of the nineties - I have no doubt that we can. This is the great project for our time, and so it must become a larger part of the debate in our politics, our businesses, our schools and our homes.\\nThe good news is that we have the resources, we have the brainpower, and we are still an economic and technological giant. In Illinois alone we have 238,000 high-tech workers. The University of Illinois at Champagne-Urbana is where Marc Andreesen developed Mosaic, the browser that made the World Wide Web what it is today. And right now at Argonne National Laboratory, scientists are developing the technology for \"grid computing\" - which IBM and others believe represents the future of the IT industry.\\nAll across America, world-class universities, first-rate research facilities and brilliant minds are on the cusp of discovering the next big idea that will lift up the quality of our lives, create millions of new jobs, and change our world. We can take comfort in knowing that, but we can\\'t take it for granted, because right now other countries are looking at places like Silicon Valley and North Carolina\\'s Research Triangle and saying \"we want that.\" They\\'re investing in better universities, expanding research budgets and venture capital, producing more science and engineering graduates, and passing innovation-friendly public policies.\\nNone of us expect or want the government to lead the next technological revolution, but I believe that we can provide the spark that fuels America\\'s innovation and competitiveness in the global economy. I believe we can do better than cutting the budget for the National Science Foundation, as this year\\'s budget has done for the first time. We can do better than falling to 10th place in the world when it comes to providing people with access to Broadband. We can do better when it comes to using technology to free ourselves from America\\'s dangerous dependence on Mideast oil. We can do better than burdening businesses with cases of class action abuse, and that\\'s why I cast a tough vote in favor of reform the other week.\\nAnd we can do better, think bigger, and act bolder when it comes to education in this country. The best part about Bill Gates\\' speech last week was when he said that our schools are in danger of becoming obsolete as tools to educate tomorrow\\'s workers for tomorrow\\'s jobs. But schools are where our children\\'s dreams begin, and so schools are where we must begin to make those dreams come true.\\nWe shouldn\\'t wait until high school either. We have to start the way Jim Barksdale of Netscape did when he gave a big grant and a lot of hope to preschoolers in Mississippi. We can\\'t leave kids behind before they even enter the first grade, and that\\'s why I\\'ll continue to focus on early childhood education as a way to give them the best start in life.\\nWe also know that some of the best ideas in education don\\'t come from Washington, but from local schools all over America. That\\'s why charter schools are a great way for us to learn from experiments in Topeka and Springfield that schools in Chicago and L.A. can replicate in their own classrooms. And because the success of your businesses depend on your ability to fill jobs with great minds, we need more corporate and private investment in our schools. John Doer\\'s work with the New Schools Venture Fund is leading the way on this front, and we should all commend him for that.\\nAs parents and citizens, each of us has a stake in making sure that our schools are doing everything possible to give our kids the competitive edge they\\'ll need in a 21st century economy. The tests we have now are great ways to gather information about what works and what doesn\\'t, but they\\'re not enough. I believe that to meet tomorrow\\'s challenges, we should create a national network of academies to train 25,000 new teachers and get them into high-need rural and urban schools. We should give local schools the latest technology training tools as John Chambers has done with the CISCO Networking Academy Program. When I was at the University of Chicago, other faculty members and myself developed a program where we essentially adopted primary schools to help them learn how to use the technological opportunities they were being offered. It\\'s not enough just to set down a computer in a classroom and walk away - we must also train teachers and administrators on how to use that computer and its technology to find new and better ways of educating our children.\\nFinally, we should work to close the gap that is widening between America and the rest of the world when it comes to math and science graduates.\\nTo do this, we must start by inspiring our children with a sense of purpose...by nurturing their imagination so that they may dream big and then work hard to reach those dreams. Too often, our children spend hours playing Playstation without ever finding out how to build Playstation. They watch television but never wonder how it\\'s put together. They surf web page after web page on the Internet, but are never taught how to design one.\\nThe incredible story of progress that is America has always been built by those who ask why, what if, and why not. Our schools must begin instilling that wonder in our children again so that their generation will unite around the next great project of our time, whether it be declaring America energy independent or launching the next great technological revolution.\\nToo often, the debate about education here in Washington degenerates to old arguments and stale ideas. And so it\\'s time to put aside partisan differences and just talk about what works for our kids and what will keep America competitive in this new century. Those are goals we all have and hopes we all share.\\nYes, the rules of the game have changed. And now it\\'s time for us to prove to the world that we can still play better than anyone. The families I\\'ve met are ready to try. Their kids are ready. TechNet is ready. And in the coming months, I will do my best to work with my colleagues and make sure our government is ready too. I want to thank TechNet for doing your part to get this dialogue going, and now I\\'d like to take a few questions from the audience. Thank you.')]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17234f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cLibpXGv-70n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLibpXGv-70n",
        "outputId": "b8201ee8-5ae6-477d-bf01-133df5c54006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  In his remarks at TechNet, Senator Obama discussed the importance of investing in technology and\n",
            "innovation to create jobs and spur economic growth. He highlighted the need for increased access to\n",
            "capital for small businesses, and emphasized the need for a comprehensive approach to energy policy,\n",
            "a more educated workforce, and investment in research and development. He also discussed the need\n",
            "for a national network of academies to train 25,000 new teachers and get them into high-need rural\n",
            "and urban schools, as well as the need to close the gap between America and the rest of the world\n",
            "when it comes to math and science graduates. He urged for a larger part of the debate in our\n",
            "politics, businesses, schools and homes to focus on the great project of our time, and for us to put\n",
            "aside partisan differences and talk about what works for our kids and what will keep America\n",
            "competitive in this new century.\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
        "\n",
        "output_summary = chain.run(docs)\n",
        "wrapped_text = textwrap.fill(output_summary, width=100)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TwWGyBwG-728",
      "metadata": {
        "id": "TwWGyBwG-728"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"Write a concise summary of the following extracting the key information:\n",
        "\n",
        "\n",
        "{text}\n",
        "\n",
        "\n",
        "CONCISE SUMMARY:\"\"\"\n",
        "PROMPT = PromptTemplate(template=prompt_template,\n",
        "                        input_variables=[\"text\"])\n",
        "\n",
        "refine_template = (\n",
        "    \"Your job is to produce a final summary\\n\"\n",
        "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
        "    \"We have the opportunity to refine the existing summary\"\n",
        "    \"(only if needed) with some more context below.\\n\"\n",
        "    \"------------\\n\"\n",
        "    \"{text}\\n\"\n",
        "    \"------------\\n\"\n",
        "    \"Given the new context, refine the original summary\"\n",
        "    \"If the context isn't useful, return the original summary.\"\n",
        ")\n",
        "refine_prompt = PromptTemplate(\n",
        "    input_variables=[\"existing_answer\", \"text\"],\n",
        "    template=refine_template,\n",
        ")\n",
        "chain = load_summarize_chain(OpenAI(temperature=0),\n",
        "                             chain_type=\"refine\",\n",
        "                             return_intermediate_steps=True,\n",
        "                             question_prompt=PROMPT,\n",
        "                             refine_prompt=refine_prompt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2R41fUDY-75W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R41fUDY-75W",
        "outputId": "dcf296bf-466d-4748-b07f-29bac5f85013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Senator Obama addressed the TechNet conference, emphasizing the importance of investing in\n",
            "technology and innovation to create jobs and strengthen the economy. He highlighted the need for\n",
            "government and private sector collaboration to ensure that the US remains competitive in the global\n",
            "economy. He also discussed the need for increased access to capital and resources for small\n",
            "businesses and entrepreneurs, as well as the need for better education and training to equip the\n",
            "next generation with the skills needed to succeed in the 21st century global economy. He proposed\n",
            "initiatives such as creating a national network of academies to train 25,000 new teachers, providing\n",
            "local schools with the latest technology training tools, and inspiring children to dream big and\n",
            "work hard.\n"
          ]
        }
      ],
      "source": [
        "output_summary = chain({\"input_documents\": docs}, return_only_outputs=True)\n",
        "wrapped_text = textwrap.fill(output_summary['output_text'],\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QD3inZBk_FFz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD3inZBk_FFz",
        "outputId": "b7ff8062-1bb0-43ad-b4eb-16dbaaed8f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Senator Obama addressed the TechNet conference, emphasizing the importance of investing in\n",
            "technology and innovation to create jobs and strengthen the economy. He highlighted the need for\n",
            "government and private sector collaboration to ensure that the US remains competitive in the global\n",
            "economy. He also discussed the need for increased access to capital and resources for small\n",
            "businesses and entrepreneurs.\n"
          ]
        }
      ],
      "source": [
        "wrapped_text = textwrap.fill(output_summary['intermediate_steps'][0],\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
